services:
  # Kafka 消息队列 (Apache 官方镜像, KRaft 模式)
  kafka:
    image: apache/kafka:3.9.0
    container_name: bilibili-kafka
    restart: unless-stopped
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093,INTERNAL://:9094
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,INTERNAL://kafka:9094
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      CLUSTER_ID: "bilibili-kafka-cluster-001"
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - bilibili-network
    healthcheck:
      test: ["CMD-SHELL", "/opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  # Redis 缓存
  redis:
    image: redis:7
    container_name: bilibili-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    networks:
      - bilibili-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # Spark Master
  spark-master:
    image: apache/spark:3.5.8
    container_name: bilibili-spark-master
    restart: unless-stopped
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "8080:8080"   # Spark Web UI
      - "7077:7077"   # Spark Master 端口
    environment:
      - SPARK_MASTER_HOST=spark-master
    volumes:
      - ./streaming:/opt/spark/streaming
    networks:
      - bilibili-network

  # Spark Worker
  spark-worker:
    image: apache/spark:3.5.8
    container_name: bilibili-spark-worker
    restart: unless-stopped
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    depends_on:
      - spark-master
    volumes:
      - ./streaming:/opt/spark/streaming
    networks:
      - bilibili-network

# 数据卷
volumes:
  kafka_data:
  redis_data:

# 网络
networks:
  bilibili-network:
    driver: bridge
